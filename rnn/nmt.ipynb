{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd72b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (1.2.1)\n",
      "Requirement already satisfied: packaging in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1.0.0->datasets) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.1.8)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tokenizers\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from tokenizers) (1.2.1)\n",
      "Requirement already satisfied: filelock in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: shellingham in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (4.13.0)\n",
      "Requirement already satisfied: anyio in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=0.16.4->tokenizers) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=0.16.4->tokenizers) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=0.16.4->tokenizers) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=0.16.4->tokenizers) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=0.16.4->tokenizers) (0.14.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from typer-slim->huggingface-hub<2.0,>=0.16.4->tokenizers) (8.1.8)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=0.16.4->tokenizers) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ketiyohannes/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=0.16.4->tokenizers) (1.3.1)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Installing collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.22.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afabd416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source_text': 'Tom tried to break up the fight.',\n",
       " 'target_text': 'Tom trat√≥ de disolver la pelea.',\n",
       " 'source_lang': 'eng',\n",
       " 'target_lang': 'spa'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Device: \", device)\n",
    "\n",
    "\n",
    "valid_set_, test_set_ = load_dataset(\n",
    "    path=\"ageron/tatoeba_mt_train\", name=\"eng-spa\",\n",
    "    split=[\"validation\", \"test\"])\n",
    "\n",
    "\n",
    "split = valid_set_.train_test_split(train_size=0.8, seed=42)\n",
    "train_set, valid_set = split[\"train\"], split[\"test\"]\n",
    "\n",
    "\n",
    "train_set[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc1499c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tokenizers\n",
    "def train_eng_spa():\n",
    "    for pair in train_set:\n",
    "        yield pair[\"source_text\"]\n",
    "        yield pair[\"target_text\"]\n",
    "\n",
    "\n",
    "max_length = 256\n",
    "vocab_size = 10000\n",
    "tokenizer_model = tokenizers.models.BPE(unk_token=\"[UNK]\") # tokenizer lib is from huggingface\n",
    "tokenizer = tokenizers.Tokenizer(tokenizer_model)\n",
    "tokenizer.enable_padding(pad_id=0, pad_token=\"<pad>\")\n",
    "tokenizer.enable_truncation(max_length=max_length)\n",
    "tokenizer.pre_tokenizer = tokenizers.pre_tokenizers.Whitespace()\n",
    "tokenizer_trainer = tokenizers.trainers.BpeTrainer(\n",
    "    vocab_size=vocab_size,\n",
    "    special_tokens=[\"<unk>\", \"<pad>\", \"<s>\", \"</s>\"]\n",
    ")\n",
    "tokenizer.train_from_iterator(train_eng_spa(), trainer=tokenizer_trainer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f700cd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72, 401, 4381]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"i like soccer\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caed19ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 396, 582, 219, 376, 3075]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<s> Me gusta el futbol\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6198be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "fields = [\"src_token_ids\", \"src_mask\", \"tgt_token_ids\", \"tgt_mask\"]\n",
    "\n",
    "class NmtPair(namedtuple(\"NmtPair\", fields)):\n",
    "    def to(self, device):\n",
    "        return NmtPair(self.src_token_ids.to(device), self.src_mask.to(device), self.tgt_token_ids.to(device), self.tgt_mask.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5f8373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_fn(batch):\n",
    "    src_txt = [pair[\"source_text\"] for pair in batch]\n",
    "    tgt_txt = [f\"<s> {pair['target_text']}</s>\" for pair in batch]\n",
    "    src_encodings = tokenizer.encode_batch(src_txt)\n",
    "    tgt_encodings = tokenizer.encode_batch(tgt_txt)\n",
    "    src_token_ids = torch.tensor([enc.ids for enc in src_encodings])\n",
    "    src_mask = torch.tensor([enc.attention_mask for enc in src_encodings])\n",
    "    tgt_token_ids = torch.tensor([enc.ids for enc in tgt_encodings])\n",
    "    tgt_mask = torch.tensor([enc.attention_mask for enc in tgt_encodings])\n",
    "    inputs = NmtPair(src_token_ids, src_mask, tgt_token_ids, tgt_mask)\n",
    "    labels = tgt_token_ids[:, 1:]\n",
    "    return inputs, labels\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, collate_fn=data_loader_fn)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, collate_fn=data_loader_fn)\n",
    "test_loader = DataLoader(test_set_, batch_size=batch_size, collate_fn=data_loader_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fab2ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=512, pad_id=0, hidden_dim=512, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_id)\n",
    "        self.encoder = nn.GRU(embed_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.decoder = nn.GRU(embed_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, pair):\n",
    "        src_embed = self.embed(pair.src_token_ids)\n",
    "        tgt_embed = self.embed(pair.tgt_token_ids)\n",
    "        src_lengths = pair.src_mask.sum(dim=1)\n",
    "        src_packed = pack_padded_sequence(\n",
    "            src_embed, lengths=src_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, hidden_states = self.encoder(src_packed)\n",
    "        outputs, _ = self.decoder(tgt_embed, hidden_states)\n",
    "        return self.out(outputs).permute(0, 2, 1)\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "model = Model(vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cc000dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea04220a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Frank'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate(model, src_txt, max_len=100, pad_id=0, sos_id=2, eos_id=3):\n",
    "    tgt_txt = \"\"\n",
    "    token_ids = []\n",
    "    for index in range(max_length):\n",
    "        batch, _ = data_loader_fn([{\"source_text\": src_txt,\n",
    "                                    \"target_text\": tgt_txt}])\n",
    "        with torch.no_grad():\n",
    "            Y_logits = model(batch.to(device))\n",
    "            Y_token_ids = Y_logits.argmax(dim=1)  # find the best token IDs\n",
    "            next_token_id = Y_token_ids[0, index]  # take the last token ID\n",
    "\n",
    "        next_token = tokenizer.id_to_token(next_token_id)\n",
    "        tgt_txt += \" \" + next_token\n",
    "        if next_token_id == eos_id:\n",
    "            break\n",
    "        return tgt_txt\n",
    "\n",
    "model.eval()\n",
    "translate(model, \"i like soccer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc1a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
